# -*- coding: utf-8 -*-
"""object_detection_yolov8l.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ic6fuo3sKjU8LEGj-BWOzzzi-8OzeKmt
"""

!pip install ultralytics flask pyngrok opencv-python > /dev/null

from pyngrok import ngrok

NGROK_AUTH_TOKEN = "33Giv8lskMrSCTMBczQWPpyazvG_6njBmKsHZ4nyzYACmJbWS"
!ngrok config add-authtoken $NGROK_AUTH_TOKEN


from flask import Flask, render_template, request, Response
from ultralytics import YOLO
import cv2, numpy as np, base64, os, time

model = YOLO("/content/best.pt")

app = Flask(__name__)


def estimate_distance(box, frame_height):
    y1, y2 = int(box[1]), int(box[3])
    box_height = y2 - y1
    if box_height == 0: return None
    k = 700  # calibration factor
    return round(k / box_height, 1)


@app.route('/')
def index():
    return render_template("index.html")

@app.route('/detect', methods=['POST'])
def detect():
    data = request.json['image']
    imgdata = base64.b64decode(data.split(',')[1])
    nparr = np.frombuffer(imgdata, np.uint8)
    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    fh, fw, _ = frame.shape

    results = model(frame)[0]
    annotated = results.plot()

    _, buffer = cv2.imencode('.jpg', annotated)
    b64 = base64.b64encode(buffer).decode("utf-8")

    detected = []
    for box in results.boxes:
        cls = model.names[int(box.cls)]
        coords = box.xyxy[0].tolist()
        dist = estimate_distance(coords, fh)
        x_center = (coords[0] + coords[2]) / 2
        pos = "left" if x_center < fw/3 else "right" if x_center > 2*fw/3 else "center"
        if dist:
            detected.append(f"{cls} {dist} meters ahead on your {pos}")
        else:
            detected.append(f"{cls} detected")

    return {"image": f"data:image/jpeg;base64,{b64}", "objects": detected}


os.makedirs("templates", exist_ok=True)
with open("templates/index.html", "w") as f:
    f.write("""
<!DOCTYPE html>
<html>
<head>
  <title>VisionTalk</title>
  <style>
    body { background:#121212; color:white; font-family:Arial; text-align:center; }
    h1 { margin:20px; }
    video, img { width:80%; border:3px solid #00ff99; border-radius:15px; margin:10px; }
    #detected { margin:20px; font-size:20px; color:#ffcc00; }
    button { background:#00ff99; border:none; padding:10px 20px; font-size:18px;
             border-radius:8px; margin:5px; cursor:pointer; }
    button:hover { background:#00cc77; }
  </style>
</head>
<body>
  <h1>üëÅÔ∏è VisionTalk: Smart Assistant</h1>
  <video id="video" autoplay playsinline></video>
  <img id="processed" />
  <div id="detected">üîä Objects will be announced</div>
  <button onclick="toggleVoice()">Toggle Voice</button>

  <script>
    let speaking = true;
    function toggleVoice(){ speaking = !speaking; }

    async function startCamera() {
      const video = document.getElementById('video');
      video.srcObject = await navigator.mediaDevices.getUserMedia({ video: true });
      setInterval(async () => {
        const canvas = document.createElement("canvas");
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext("2d").drawImage(video, 0, 0);
        const data = canvas.toDataURL("image/jpeg");

        const res = await fetch("/detect", {
          method: "POST",
          headers: {"Content-Type": "application/json"},
          body: JSON.stringify({image: data})
        });
        const result = await res.json();
        document.getElementById("processed").src = result.image;

        if(result.objects.length > 0){
          const msg = "I see " + result.objects.join(", ");
          document.getElementById("detected").innerText = msg;
          if(speaking){
            const utter = new SpeechSynthesisUtterance(msg);
            speechSynthesis.speak(utter);
          }
        }
      }, 2000);
    }
    startCamera();
  </script>
</body>
</html>
    """)


public_url = ngrok.connect(5000)
print("üåç Public URL:", public_url)

from threading import Thread
def run_app():
    app.run(port=5000)

Thread(target=run_app).start()

# Keep notebook alive
while True:
    time.sleep(60)

